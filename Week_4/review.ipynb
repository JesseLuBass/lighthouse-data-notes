{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2d4d83d",
   "metadata": {},
   "source": [
    "Restful api:\n",
    "* uniform interface\n",
    "* client server seperation\n",
    "* stateless design\n",
    "* layered system \n",
    "* cache on demand \n",
    "* code on demand \n",
    "\n",
    "Architetectural design for a certain kind of software "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c249ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf13e4bf",
   "metadata": {},
   "source": [
    "Relational database\n",
    "* postgres primary & foregin keys \n",
    "* star * snow flake patterns \n",
    "* RDBMS - relational database management system - mySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fcf445",
   "metadata": {},
   "source": [
    "dataframe boolearn operator eq, ne, lt, gt, le, ge "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6e251",
   "metadata": {},
   "source": [
    "reductions : empty(), all(), all(), bool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91bb220",
   "metadata": {},
   "source": [
    "to evaluate single-element pandas objects in a boolean context, use the method bool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d7c6cc",
   "metadata": {},
   "source": [
    "pandas handles element-wise comparison between different array-like objects of the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ceec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan == np.nan\n",
    "False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5697dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.decribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16c57b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "For a non-numerical Series object, describe() will give a simple summary of the number of unique values and the most frequently occurring values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc386af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "          A         B         C\n",
    "0 -0.327863 -0.946180 -0.137570\n",
    "1 -0.186235 -0.257213 -0.486567\n",
    "2 -0.507027 -0.871259 -0.111110\n",
    "3  2.000339 -2.430505  0.089759\n",
    "4 -0.321434 -0.033695  0.096271\n",
    "\n",
    "In [112]: df1.idxmin(axis=0)\n",
    "Out[112]: \n",
    "A    2\n",
    "B    3\n",
    "C    1\n",
    "dtype: int64\n",
    "\n",
    "In [113]: df1.idxmax(axis=1)\n",
    "Out[113]: \n",
    "0    C\n",
    "1    A\n",
    "2    C\n",
    "3    A\n",
    "4    C\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420204d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterrows() allows you to iterate through the rows of a dataframe as series object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd36f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "itertuples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc17c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eab006",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=[bool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f308531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a372cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['E'].isin(['one','two'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c0f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(pieces) # joins all the roles together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner join is done automatically with merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "By group by, we are referring to a process involving the following steps:\n",
    "\n",
    "Splitting the data into groups based on some criteria\n",
    "Applying a function to each group independently\n",
    "Combining the results into a data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7293f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('A').agg({'C': np.sum, 'D': np.max})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b8feeb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-03b88d16eac0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m df = pd.DataFrame({'A': ['one', 'one', 'two', 'three'] * 3,\n\u001b[0m\u001b[0;32m      2\u001b[0m                        \u001b[1;34m'B'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'B'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'C'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                        \u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'foo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'foo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'foo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bar'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bar'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bar'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                        \u001b[1;34m'D'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                        'E': np.random.randn(12)})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': ['one', 'one', 'two', 'three'] * 3,\n",
    "                       'B': ['A', 'B', 'C'] * 4,\n",
    "                       'C': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n",
    "                       'D': np.random.randn(12),\n",
    "                       'E': np.random.randn(12)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5471435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34330a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for dupes for Id\n",
    "idsUnique = len(set(df_train.Id))\n",
    "idsTotal = df_train.shape[0]\n",
    "idsdupe = idsTotal - idsUnique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe5177",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(df_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most correlated features with SalePrice, emphasis correlation with SalePrice\n",
    "corrmat = df_train.corr()\n",
    "top_corr_features = corrmat.index[abs(corrmat[\"SalePrice\"])>0.5]\n",
    "plt.figure(figsize=(10,10))\n",
    "g = sns.heatmap(df_train[top_corr_features].corr(),annot=True,cmap=\"RdYlGn_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd745c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data\n",
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f0fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the names of columns with missing values\n",
    "cols_with_missing = missing_data[missing_data.Percent > 0].index.tolist()\n",
    "# remove column names that are already removed from dataset\n",
    "missing_cols = list(set(cols_with_missing) - set(to_drop))\n",
    "# check the datatype\n",
    "df_train.dtypes[missing_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ada549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b0ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_item(row):\n",
    "    if not np.isnan(row[‘Item_Weight’]):\n",
    "        return row[‘Item_Weight’]\n",
    "    else:\n",
    "        mean = mean_weights.loc[row.Item_Type, ‘Item_Weight’]\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc175aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm \n",
    "naive bayes\n",
    "ensemble technique \n",
    "xgboost\n",
    "gradient boost\n",
    "random forest \n",
    "decision tree\n",
    "glm\n",
    "logistic regression\n",
    "gradient descent \n",
    "stochastic gradient descent\n",
    "polynomial regression\n",
    "linear regression\n",
    "KNeighborsClassifier\n",
    "grid search \n",
    "regularization \n",
    "ridge regression \n",
    "lasso regression \n",
    "elasticnet regression\n",
    "\n",
    "density model\n",
    "hierachical model\n",
    "centroid model - kmeans \n",
    "\n",
    "dimensionality reduction - pca ,linear discriminant analysis, multidimensional scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a303d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfeeec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the same model as before"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
